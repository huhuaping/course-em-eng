{
  "hash": "b20c2fee256d38c7eaa8016f38787749",
  "result": {
    "engine": "knitr",
    "markdown": "---\npagetitle: \"Advanced Econometrics III\"\nunitcode: \"(Econometrics III)\"\nunitname: \"Advanced Econometrics III\"\nauthor: \"Hu Huaping (胡华平)\"\nemail: \"huhuaping01 at hotmail.com\"\nuniversity: \"NWAFU (西北农林科技大学)\"\ndepartment: \"School of Economics and Management (经济管理学院)\"\nsubtitle: \"Chapter 18. Why Should We Concern SEM?\"\ndate: \"2024-09-25\"\n#keep-md: true\nformat: \n  revealjs: \n    footer: \"Chapter 18. Why Should We Concern SEM?\"\n---\n\n\n\n\n## 环境准备{visibility=\"hidden\"}\n\n\n\n\n\n\n\n\n\n\n\n# 标题页 {visibility=\"hidden\"}\n\n## <br>Advanced Econometrics III{background-image=\"pic/slide-front-page.jpg\" #etc5523-title .center-h style=\"font-size:65px\" visibility=\"uncounted\"}\n\n### **(Econometrics III)**{.monash-black .center-h style=\"font-family:'sans-serif'; font-size:65px !important\"}\n\n\n### Chapter 18. Why Should We Concern SEM?{.monash-blue .center-h style=\"font-size:70px !important\"}\n\n<br>\n\n#### Hu Huaping (胡华平) {.center-h .monash-black}\n\n#### huhuaping01 at hotmail.com {.center-h .monash-black style=\"font-family:'sans-serif';\"}\n\n#### School of Economics and Management (经济管理学院) {.center-h .monash-black}\n\n\n#### 2024-09-25 {.center-h .monash-black}\n\n\n\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\n\n\n\n# Part 2：Simultaneous-Equation Models (SEM){.monash-bg-blue .mcenter visibility=\"uncounted\"}\n\n::: {.font-110}\n\nChapter 17. Endogeneity and Instrumental Variables\n\n[Chapter 18. Why Should We Concern SEM ?]{.red}\n\nChapter 19. What is the Identification Problem?\n\nChapter 20. How to Estimate SEM ?\n\n:::\n\n\n::: {.notes}\nIn the following three chapters, we will focus on simultaneous equation models.\n:::\n\n\n# Chapter 18. Why Should We Concern SEM ?{#chpt18 .monash-bg-blue .mcenter}\n\n[18.1 The Nature of Simultaneous-Equation Models](#nature)\n\n[18.2 Notes and Relative Definitions](#notation)\n\n[18.3 Is OLS Method Still applicable?](#OLS-apply)\n\n::: {.notes}\nFirstly, let us answer the question that why should we concern SEM ?\n:::\n\n\n# 18.1 The Nature of Simultaneous-Equation Models{#nature .monash-bg-blue .mcenter}\n\n::: {.notes}\nSo, the most important issue we should know about is the nature of the SEM.\n:::\n\n## Definition and basic format of SEM\n\n- **Simultaneous Equations Models (SEM)**: A system of equations consisting of several equations with interrelated or jointly influence.\n\n\n\n- The basic and simple SEM is\n\n$$\n\\begin{cases}\n\\begin{align}\nY_{1 i}=\\beta_{10}+\\gamma_{12} Y_{2 i}+\\beta_{11} X_{1 i}+u_{i1} \\\\\nY_{2 i}=\\beta_{20}+\\gamma_{21} Y_{1 i}+\\beta_{21} X_{1 i}+u_{i2}\n\\end{align}\n\\end{cases}\n$$\n\n\n::: {.notes}\nNext, I will show you four SEM examples from classical economic textbooks, and another two real life SEM examples.\n:::\n\n## Macroeconomics SEM Examples\n\n<!-- insert some images here -->\n\n##\n\n### Demand-and-Supply System\n\n**Demand-and-Supply System**:\n\n$$\n\\begin{cases}\n\\begin{align}\n\\text { Demand function: } & {Q_{t}^{d}=\\alpha_{0}+\\alpha_{1} P_{t}+u_{1t}, \\quad \\alpha_{1}<0} \\\\\n{\\text { Supply function: }} & {Q_{t}^{s}=\\beta_{0}+\\beta_{1} P_{t}+u_{2t}, \\quad \\beta_{1}>0} \\\\\n{\\text {Equilibrium condition: }} & {Q_{t}^{d}=Q_{t}^{s}}\n\\end{align}\n\\end{cases}\n$$\n\n::: {.notes}\nThis slide shows the classic demand and supply SEM.The first eq is the demand function, and the second one is the supply function, the last one is the market equilibrium identity.\n:::\n\n##\n\n### Keynesian Model of Income Determination\n\n**Keynesian Model of Income Determination**:\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= \\beta_0+\\beta_1Y_t+\\varepsilon_t &&\\text{(consumption function)}\\\\\nY_t &= C_t+I_t &&\\text{(income identity)}\n\\end{align}\n\\end{cases}\n$$\n\n::: {.notes}\n/'keinziən/This slide shows the Keynesian Model of Income Determination, which consists of two equations.And I will show you more details later in this chapter.\n:::\n\n\n##\n\n### The IS Model\n\nMacroeconomics goods market equilibrium model, also known as **IS Model**:\n\n$$\n\\begin{cases}\n\\begin{align}\n\\text { Consumption function: } & C_{t}=\\beta_{0}+\\beta_{1} Y_{d t} +u_{1t} & <\\beta_{1}<1 \\\\\n\\text { Tax function: } & T_{t}=\\alpha_{0}+\\alpha_{1} Y_{t} +u_{2t}& \\quad 0<\\alpha_{1}<1  \\\\\n\\text { Investment function: } & I_{t}=\\gamma_{0}+\\gamma_{1} r_{t} +u_{3t} \\\\\n\\text { Definition: } & \\gamma_{d t}=Y_{t}-T_{t} \\\\\n\\text { Government expenditure: } & G_{t}=\\bar{G} \\\\\n\\text { National income identity: } & Y_{t}=C_{t}+I_{t}+G_{t}\n\\end{align}\n\\end{cases}\n$$\n\n\n>where:\n>  $Y=$ national income;  $Y_d=$ disposable income;  $r=$ interest rate;  $\\bar{G}=$ given level of government expenditure\n\n::: {.notes}\nHere, the IS system contains totally six equations.\n:::\n\n##\n\n###  The LM Model\n\nMacroeconomics money market equilibrium system, also known as **LM Model**:\n\n$$\n\\begin{cases}\n\\begin{align}\n{\\text { Money demand function: }} & {M_{t}^{d}=a+b Y_{t}-c r_{t}} +u_{t} \\\\\n{\\text { Money supply function: }} & {M_{t}^{s}=\\bar{M}} \\\\\n{\\text { Equilibrium condition: }} & {M_{t}^{d}=M_{t}^{s}}\n\\end{align}\n\\end{cases}\n$$\n\n>Where:\n>  $Y=$ income;  $r=$ interest rate;  $\\bar{M}=$ assumed level of money supply.\n\n::: {.notes}\nThus, the LM system contains totally 3 equations.\n:::\n\n##\n\n###  Klein's model I\n\n**Klein's model I**：\n\n$$\n\\begin{cases}\n\\begin{align}\n\\text { Consumption function: }  & C_{t}=\\beta_{0}+\\beta_{1} P_{t}+\\beta_{2}\\left(W+W^{\\prime}\\right)_{t}+\\beta_{3} P_{t-1}+u_{ t1} \\\\\n\\text { Investment function: } & I_{t} =\\beta_{4}+\\beta_{5} P_{t}+\\beta_{6} P_{t-1}+\\beta_{7} K_{t-1}+u_{ t2} \\\\\n\\text { Demand for labor: }\n& w_{t}= \\beta_{8}+\\beta_{9}\\left(Y+T-W^{\\prime}\\right)_{t}  +\\beta_{10}\\left(Y+T-W^{\\prime}\\right)_{t-1}+\\beta_{11} t+u_{ t3} \\\\ \\text { Identity: } & Y_{t} = C_{t}+I_{t}+C_{t} \\\\\n\\text { Identity: }  & Y_{t}=W_{t}^{\\prime}+W_{t}+P_{t} \\\\\n\\text { Identity: }  & K_{t}=K_{t-1}+I_{t}\n\\end{align}\n\\end{cases}\n$$\n\n>Where:\n>  $C=$ consumption expenditure;  $Y=$ income after tax;  $P=$ proﬁts;  $W=$ private wage bill;  $W^{\\prime}=$ government wage bill;  $K=$ capital stock;  $T=$ taxes.\n\n::: {.notes}\nThis slide shows the macroeconomic Klein's model I. And it contains three stochastic equations and three identities.\n:::\n\n## Microeconomic SEM Examples\n\n<!-- insert some images here -->\n\n##\n\n### Murder Rates and Size of the police Force\n\nCities often want to determine how much additional **law enforcement** will decrease their **murder rates**.\n\n$$\n\\begin{cases}\n\\begin{align}\n\\operatorname{murdpc} &=\\alpha_{1} \\operatorname{polpc}+\\beta_{10}+\\beta_{11} \\text {incpc}+u_{1} \\\\\n\\text { polpc } &=\\alpha_{2} \\operatorname{murdpc}+\\beta_{20}+\\text { other factors. }\n\\end{align}\n\\end{cases}\n$$\n\n\n> Where :\n>  $murdpc =$ murders per capita;  $polpc =$ number of police officers per capita;  $incpc =$ income per capita.\n\n::: {.notes}\nHere, we will see an microeconomic real life example.we assumed that merder rates is determinded by numbers of police officers and income per capita.Meanwhile, the number of police officers will also be affected by murder rates and other factors within city districts.\n:::\n\n##\n\n### Housing Expenditures and Saving\n\nFor a random household in the population, we assume that annual **housing expenditures** and **saving** are jointly determined by:\n\n$$\n\\begin{cases}\n\\begin{align}\n\\text {housing } & =\\alpha_{1} \\text {saving}+\\beta_{10}+\\beta_{11} \\text {inc}+\\beta_{12} e d u c+\\beta_{13} \\text {age}+u_{1} \\\\\n\\text {saving} &=\\alpha_{2} \\text {housing }+\\beta_{20}+\\beta_{21} \\text {inc}+\\beta_{22} e d u c+\\beta_{23} \\text {age}+u_{2}\n\\end{align}\n\\end{cases}\n$$\n\n> Where:\n>  $inc =$ annual income;  $saving =$ household saving;  $educ =$ education measured in years;  $age =$ age measured in years.\n\n\n::: {.notes}\nAnother real life example is the housing expenditures and saving system.as you know, housing expenditures and savings are jointly determinded by income, education, age, and the disturbances.Meanwhile, there will be reverse causality effect between housing expenditures and houshold saving.\n:::\n\n##\n\n### Labor market of married, Working Women\n\nLet's consider the labor market for married women already in the workforce.\n\n\n$$\n\\begin{alignedat}{8}\n\\text { hours } & =\\alpha_1 \\log ( wage)+\\beta_{10}+\\beta_{11} { educ }+\\beta_{12} age \\\\&+\\beta_{13}  { kidslt6 }  +\\beta_{14} { nwifeinc }+u_1  &\\text{(supply)}\\\\\n\\log ({ wage }) &=\\alpha_2 { hours }+\\beta_{20}+\\beta_{21} { educ }+\\beta_{22} { exper }  \\\\&+\\beta_{23} { exper }^2+ u_2  & \\text{(demand)}\\\\\n\\end{alignedat}\n$$\n\n\n- In the demand function, we write the wage offer as a function of hours and the usual productivity variables.\n\n- All variables except `hours` and `log(wage)` are assumed to be exogenous.\n\n- `educ` might be correlated with omitted `ability` in either equation. Here, we just ignore the omitted ability problem.\n\n::: {.notes}\nsource: **Wooldridge, J.M. Introductory econometrics: a modern approach[M].** Seventh edition. Australia: Cengage, 2020. Example 16.5: labor Supply of married, Working Women.\n:::\n\n\n## The Nature of SEM\n\nThe essence of simultaneous equation model is **endogenous variable** problem:\n\n\n- Each of these equations has its economic **causality effect**.\n\n- Some of these equations contain **endogenous variables**.\n\n- Sample data is only the end result of various variables, which lies  complex causal interaction behind them.\n\n- Estimation all of the **parameters** directly by OLS method may induce problems.\n\n::: {.notes}\nSo, What are the characteristics of the simultaneous equation model?\n:::\n\n\n## Truffles example\n\n<!-- some images here -->\n\n\n##\n\n### The story\n\n**Trufﬂes** are delicious food materials. They are edible fungi that grow below the ground. Consider a supply and demand model for trufﬂes:\n\n$$\n\\begin{cases}\n\\begin{align}\n\\text { Demand: } & Q_{di}=\\alpha_{1}+\\alpha_{2} P_{i}+\\alpha_{3} P S_{i}+\\alpha_{4} D I_{i}+e_{d i} \\\\\n\\text { Supply: } & Q_{si}=\\beta_{1}+\\beta_{2} P_{i}+\\beta_{3} P F_{i}+e_{s i}\\\\\n\\text { Equity: } & Q_{di}= Q_{si}\n\\end{align}\n\\end{cases}\n$$\n\n> where:\n-  $Q_i=$ the quantity of trufﬂes traded in a particular marketplace; -  $P_i=$ the market price of trufﬂes; -  $PS_i=$ the market price of a substitute for real trufﬂes; -  $DI_i=$ per capita monthly disposable income of local residents; -  $PF_i=$ the price of a factor of production, which in this case\nis the hourly rental price of trufﬂe-pigs used in the search process.\n\n::: {.notes}\nSo, let us sum up this section with the truffles example.We will just walk through the sigle equation thought with the data set.And you should think about the difference between sigle equation model and SEM.\n:::\n\n##\n\n### Model variables\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-c3b15e431a33df261ac6\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-c3b15e431a33df261ac6\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>All variables<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\"],[\"P\",\"Q\",\"PS\",\"DI\",\"PF\"],[\"market price of truffles\",\"market quantity of truffles\",\"market price of substitute\",\"disposable income\",\"rental price of truffles-pigs\"],[\"dollar/ounce\",\"ounce\",\"dollar/ounce\",\"dollar/capita, monthly\",\"dollar/hour\"]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>vars<\\/th>\\n      <th>label<\\/th>\\n      <th>measure<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"tip\",\"pageLength\":6,\"rownames\":false,\"columnDefs\":[{\"className\":\"dt-center\",\"targets\":\"_all\"},{\"visible\":false,\"targets\":0},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"vars\",\"targets\":1},{\"name\":\"label\",\"targets\":2},{\"name\":\"measure\",\"targets\":3}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[6,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n::: {.notes}\n松露案例：变量说明案例来源：Hill, R. C., W. E. Griffiths and G. C. Lim. Principles of Econometrics 4th Edition  [M], Wiley, 2011. chpt 11。实例参考：[PoE with R](https://bookdown.org/ccolonescu/RPoE4/simultaneous-equations-models.html)\n:::\n\n\n##\n\n###  The data set\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-596db8e66301cc1e6d41\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-596db8e66301cc1e6d41\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption>Truffles data set (n = 30)<\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\",\"21\",\"22\",\"23\",\"24\",\"25\",\"26\",\"27\",\"28\",\"29\",\"30\"],[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30],[29.64,40.23,34.71,41.43,53.37,38.52,54.33,40.56,67.34999999999999,49.65,58.17,66.87,49.95,64.95,52.68,61.2,80.55,89.94,70.77,57.33,46.23,77.43000000000001,83.01000000000001,70.70999999999999,66.75,76.8,83.7,81,88.44,105.45],[19.89,13.04,19.61,17.13,22.55,6.37,15.02,10.22,23.64,16.12,24.55,18.92,11.94,18.93,12.6,20.49,22.94,21.08,16.68,17.61,16.62,20.99,24.53,19.67,23.29,16.64,20.81,14.95,26.27,20.65],[19.97,18.04,22.36,20.87,19.79,15.98,17.94,17.09,22.72,15.74,24.64,23.7,15.93,23.34,15.21,26.04,22.95,27.1,23.65,20.06,26.38,24.28,26.64,22.65,19.68,23.82,28.98,18.52,28.16,28.43],[2.103,2.043,1.87,1.525,2.709,2.489,2.294,2.196,3.885,3.169,2.623,3.007,3.367,3.29,3.746,3.518,4.381,4.121,3.82,4.398,3.764,4.524,4.815,3.67,4.392,4.603,4.632,4.894,5.125,4.836],[10.52,19.67,13.74,17.95,13.71,24.95,24.17,23.61,19.52,20.03,15.38,22.98,25.76,25.17,25.82,19.31,26.02,29.65,27.45,18,18.87,24.58,25.25,24.24,22.63,27.35,27.8,30.34,24.12,34.01]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>id<\\/th>\\n      <th>P<\\/th>\\n      <th>Q<\\/th>\\n      <th>PS<\\/th>\\n      <th>DI<\\/th>\\n      <th>PF<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"tip\",\"pageLength\":8,\"rownames\":false,\"columnDefs\":[{\"className\":\"dt-center\",\"targets\":\"_all\"},{\"visible\":false,\"targets\":0},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"id\",\"targets\":1},{\"name\":\"P\",\"targets\":2},{\"name\":\"Q\",\"targets\":3},{\"name\":\"PS\",\"targets\":4},{\"name\":\"DI\",\"targets\":5},{\"name\":\"PF\",\"targets\":6}],\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[8,10,25,50,100]}},\"evals\":[],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n##\n\n### The Scatter plot (P VS Q)\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/lecture-18-sem-why.rmarkdown/fig-scatter-truffles-1.png){#fig-scatter-truffles fig-align='center' width=1344}\n:::\n:::\n\n\n\n\n##\n\n### The Scatter matrix\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](images/lecture-18-sem-why.rmarkdown/fig-scatter-matrix-1.png){#fig-scatter-matrix fig-align='center' width=1344}\n:::\n:::\n\n\n\n\n##\n\n### The simple linear regression\n\nLet's start with the simplest linear regression model.\n\nGenerally, we use price (P) and output (Q) data to directly conduct simple linear regression modeling:\n\n$$\n\\begin{cases}\n\\begin{align}\nP & = \\hat{\\beta}_1+\\hat{\\beta}_2Q +e_1 && \\text{(simple P model)}\\\\\nQ & = \\hat{\\beta}_1+\\hat{\\beta}_2P +e_2  && \\text{(simple Q model)}\n\\end{align}\n\\end{cases}\n$$\n\n\n\n::: {.notes}\n从最简单线性回归模型开始。通常我们会使用价格(P)和产量(Q)数据直接做简单线性回归建模：\n:::\n\n##\n\n### The simple linear regression\n\nAs we all know, the linear regression of two variables is asymmetrical, so there is:\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n- the simple **Price** regression is:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n$$\n\\begin{alignedat}{999}\n\\begin{split}\n&\\widehat{P}=&&+23.23&&+2.14Q_i\\\\ \n&(s)&&(12.3885)&&(0.6518)\\\\ \n&(t)&&(+1.87)&&(+3.28)\\\\ \n&(fit)&&R^2=0.2780&&\\bar{R}^2=0.2522\\\\ \n&(Ftest)&&F^*=10.78&&p=0.0028\n\\end{split}\n\\end{alignedat}\n$$\n:::\n\n\n\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n\n- the simple **Quantity** regression  is:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n$$\n\\begin{alignedat}{999}\n\\begin{split}\n&\\widehat{Q}=&&+10.31&&+0.13P_i\\\\ \n&(s)&&(2.5863)&&(0.0396)\\\\ \n&(t)&&(+3.99)&&(+3.28)\\\\ \n&(fit)&&R^2=0.2780&&\\bar{R}^2=0.2522\\\\ \n&(Ftest)&&F^*=10.78&&p=0.0028\n\\end{split}\n\\end{alignedat}\n$$\n:::\n\n\n\n\n\n\n:::\n\n::::\n\n::: {.notes}\n我们都知道，两个变量的线性回归是不对称的，因此有：\n:::\n\n##\n\n### The sample regression line (SRL)\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![SRL of the Price model](images/lecture-18-sem-why.rmarkdown/fig-scatter-truffles-left-1.png){#fig-scatter-truffles-left fig-align='center' width=576}\n:::\n:::\n\n\n\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![SRL of the Quantity model](images/lecture-18-sem-why.rmarkdown/fig-scatter-truffles-right-1.png){#fig-scatter-truffles-right fig-align='center' width=576}\n:::\n:::\n\n\n\n\n:::\n\n::::\n\n\n::: {.notes}\nSo, we can not distinguish the supply curve or the demand curve here.\n:::\n\n##\n\n### The multi-variables regression model (1/2)\n\nOf course, we can also use more independent variables X to build the regression models:\n\n\n$$\n\\begin{cases}\n\\begin{align}\nP & = \\hat{\\beta}_1+\\hat{\\beta}_2Q +\\hat{\\beta}_3DI+\\hat{\\beta}_2PS +e_1 && \\text{(added P model)}\\\\\nQ & = \\hat{\\beta}_1+\\hat{\\beta}_2P +\\hat{\\beta}_2PF+e_2  && \\text{(added Q model)}\n\\end{align}\n\\end{cases}\n$$\n\n\n\n::: {.notes}\nOf course, we can also use more independent variables X to build the regression models.We tried hard to make these supply or demand equations more \"reasonable\" and \"believable\".\n:::\n\n##\n\n### The multi-variables regression model (2/2)\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n- Result of multi-vars **Price** regression model is:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n$$\n\\begin{alignedat}{999}\n\\begin{split}\n&\\widehat{P}=&&-48.68&&+2.05Q_i&&+3.16DI_i\\\\ \n&(s)&&(5.0047)&&(0.2731)&&(1.1409)\\\\ \n&(t)&&(-9.73)&&(+7.50)&&(+2.77)\\\\ \n&(cont.)&&+0.36PS_i&&+2.39PF_i &&\\\\ \n&(s)&&(0.2674)&&(0.2184) &&\\\\ \n&(t)&&(+1.36)&&(+10.96) &&\\\\ \n&(fit)&&R^2=0.9658&&\\bar{R}^2=0.9603 &&\\\\ \n&(Ftest)&&F^*=176.23&&p=0.0000 &&\n\\end{split}\n\\end{alignedat}\n$$\n:::\n\n\n\n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n\n- Result of multi-vars **Quantity** regression model:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n$$\n\\begin{alignedat}{999}\n\\begin{split}\n&\\widehat{Q}=&&+18.88&&+0.34P_i&&-0.40DI_i\\\\ \n&(s)&&(2.3480)&&(0.0451)&&(0.5238)\\\\ \n&(t)&&(+8.04)&&(+7.50)&&(-0.77)\\\\ \n&(cont.)&&+0.08PS_i&&-0.96PF_i &&\\\\ \n&(s)&&(0.1115)&&(0.0918) &&\\\\ \n&(t)&&(+0.71)&&(-10.51) &&\\\\ \n&(fit)&&R^2=0.9069&&\\bar{R}^2=0.8920 &&\\\\ \n&(Ftest)&&F^*=60.88&&p=0.0000 &&\n\\end{split}\n\\end{alignedat}\n$$\n:::\n\n\n\n\n:::\n\n::::\n\n::: {.notes}\nHowever, we know that in the demand-supply SEM, reverse causility effect will existbetween the price  and quantity variables.So, these simple OLS estimates are unreliable with our intuition.\n:::\n\n\n# 18.2 Notations and Definitions{#notation .monash-bg-blue .mcenter}\n\n::: {.notes}\nIn this section, I will give you some important definition and notations about SEM.\n:::\n\n## Structural SEM\n\n<!-- some images insert here -->\n\n##\n\n### Algebraic expression (A)\n\n**Structural equations**: System of equations that directly characterize economic structure or behavior.\n\nThe **algebraic expression** of structural SEM is：\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n\n::: {.notes}\nalgebraic  /ˌældʒɪˈbreɪɪk/In fact, all examples we have seen in the former section are structural SEM.___So we donote the generalized algebraic expression of structural SEM as follows.\n:::\n\n##\n\n### Structural coefficients\n\n**Structural coefficients**: Parameters in structural equation that represents an economic outcome or behavioral relationship, including:\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n>- **[En]{.red}dogenous structural coefficients**:  $\\gamma_{11}, \\gamma_{21},\\cdots, \\gamma_{m1}; \\cdots; \\gamma_{1m}, \\gamma_{2m},\\cdots, \\gamma_{mm}$ \n\n>- **[Ex]{.red}ogenous structural coefficients**:  $\\beta_{11}, \\beta_{21},\\cdots, \\beta_{m1}; \\cdots; \\beta_{1m}, \\beta_{2m},\\cdots, \\beta_{mm};$ \n\n::: {.notes}\nFirstly, let's define the structural coefficients.**Structural coefficients** are Parameters in structural SEM that represents an economic outcome or behavioral relationship, including Endogenous structural coefficients (here denoted as ...) and Exogenous structural coefficients (here denoted as ...) .\n:::\n\n##\n\n### Structural variables\n\n- **Endogenous variables**: Variables determined by the model.\n\n- **Predetermined variables**：Variables which values are not determined by the model in the **current** time period.\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n**Endogenous variables**:\n\n- Such as:  $Y_{t1};Y_{t2}; \\cdots; Y_{tm}$ \n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"40%\"}\n\n**Predetermined variables**:\n\n- Such as:  $X_{..}$ \n\n:::\n\n::::\n\n::: {.notes}\nAnother important concept is the structural variable, which includes endogenouse variable and predeterminded variable.Endogenous variables are Variables determined by the model.Predetermined variables are Variables which values are not determined by the model in the current time period.We assumed the endogenous variables in this SEM includes all Y_ts, and the predeterminded vairiables include all X_ts.\n:::\n\n##\n\n### Predetermined variables\n\n**Predetermined variables**: Variables which values are not determined by the model in the **current** time period, including:\n\n- the **exogenous variables**\n\n- the **lagged endogenous variables**.\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n\n::: {.notes}\nYou should remind that the predetermined variables  consist of both the exogenous variables and thelagged endogenous variables.\n:::\n\n##\n\n### Predetermined variables\n\n\n- **[Ex]{.red}ogenous variables**: The variables not determined by the model, neither in the **current period** nor in the **lagged period**.\n\n- **Lagged [en]{.red}dogenous variables**: The lag variable of the endogenous variable in the current period。\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n> **current period [ex]{.red}ogenous**:\n-  $X_{t1}, X_{t2},\\cdots, X_{tk}$ .\n\n\n> **lagged period [ex]{.red}dogenous**:\n- lagged from  $X_{t1}$ :  $X_{t-1,1}; X_{t-2,1};\\cdots; X_{t-(T-1),1}$  - and lagged from  $X_{tk}$ :  $X_{t-1,k}; X_{t-2,k};\\cdots; X_{t-(T-1),k}$  -  $\\cdots$ \n\n:::\n\n\n::: {.column width=\"40%\"}\n\n> **lagged [en]{.red}dogenous**:\n- lagged from  $Y_{t1}$ :  $Y_{t-1,1}; Y_{t-2,1}; \\cdots, Y_{t-(T-1),1}$  - and lagged  from  $Y_{tm}$ ：  $Y_{t-1,m}; Y_{t-2,m}; \\cdots;Y_{t-(T-1),m}$  -  $\\cdots$ \n:::\n\n::::\n\n::: {.notes}\n> So, you may get two types Exogenous variables, which are current period exogenous, such as all X_ts, and Lagged [en]{.red}dogenous variables, such as all X_t-s.\n:::\n\n##\n\n### Predetermined coefficients\n\n**Predetermined coefficients**: coefficients before predetermined variables.\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n\n> Such as:  $\\beta_{11}, \\beta_{21},\\cdots, \\beta_{12}; \\cdots; \\beta_{k2}, \\beta_{1m},\\cdots, \\beta_{km}$\n\n\n::: {.notes}\nOf course, we may denote coefficients before predetermined variables as **Predetermined coefficients**.\n:::\n\n##\n\n### Algebraic expression (B)\n\nBy simple transformation, the **algebraic expression** of SEM can also show as:\n\n::: {.font-95}\n\n$$\nA: \\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n:::\n\n::: {.font-90}\n\n$$\nB: \\begin{cases}\n\\begin{alignat}{5}\n\\gamma_{11}Y_{t1} &+ \\gamma_{21}Y_{t2}&+\\cdots &+\\gamma_{m-1,1}Y_{t,m-1} &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{t1}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &=\\varepsilon_{t1} \\\\\n\\gamma_{12}Y_{t1} &+\\gamma_{22}Y_{t2} &+   \\cdots&+\\gamma_{m-1,2}Y_{t,m-1} &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &= \\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\n\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}&+ \\cdots &+\\gamma_{m-1,m}Y_{t,m-1} & +\\gamma_{mm}Y_{tm}  &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &=\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n:::\n\n\n::: {.notes}\nBy simple transformation, we can also obtain another **algebraic expression** (B) of SEM as show in this slide.\n:::\n\n##\n\n### Matrix expression (1/2)\n\nWith the Matrix language, the **matrix expression** of SEM was noted as:\n\n$$\n\\begin{equation}\n\\begin{bmatrix}\nY_1 & Y_2 & \\cdots & Y_m \\\\\n\\end{bmatrix} _t\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1m} \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n\\gamma_{m1} & \\gamma_{m2} & \\cdots & \\gamma_{mm} \\\\\n\\end{bmatrix} + \\\\\n\\begin{bmatrix}\nX_1 & X_2 & \\cdots & X_m \\\\\n\\end{bmatrix} _t\n\\begin{bmatrix}\n\\beta_{11} & \\beta_{12} & \\cdots & \\beta_{1m} \\\\\n\\beta_{21} & \\beta_{22} & \\cdots & \\beta_{2m} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\beta_{k1} & \\beta_{k2} & \\cdots & \\beta_{km} \\\\\n\\end{bmatrix} \\\\ =\n\\begin{bmatrix}\n\\varepsilon_1 & \\varepsilon_2 & \\cdots & \\varepsilon_m \\\\\n\\end{bmatrix} _t\n\\end{equation}\n$$\n\n::: {.notes}\nHere, we arranged the matrix expression of SEM based on former algebraic expression B.\n:::\n\n##\n\n### Matrix expression (2/2)\n\nFor Simplicity, we can generized the **matrix expression** of SEM :\n\n$$\n\\begin{aligned}\n& \\boldsymbol{y^{\\prime}_t} \\boldsymbol{\\Gamma} &+ & \\boldsymbol{x^{\\prime}_t} \\boldsymbol{B} &= & \\boldsymbol{{\\varepsilon^{\\prime}_t}} \\\\\n&(1 \\ast m)(m \\ast m) & & (1 \\ast k)(k \\ast m) & & (1 \\ast m)\n\\end{aligned}\n$$\n\n::: {.callout-note}\n**where**：\n\n- Bold upper letter and greek means a **matrix**\n\n- Bold lower letter and greek means a **column vector**\n\n:::\n\n\n::: {.notes}\nFor Simplicity, we can generized the **matrix expression** of SEM as follow.> we should remind that：- the dimension of the vector and matrix is important;- and matrix compatibility  /kəmˌpætəˈbɪləti/ is needed in matrix calculation.\n:::\n\n##\n\n### Endogenous coefficients matrix\n\nFor the **[En]{.red}dogenous parameter matrix**  $\\boldsymbol{\\Gamma}$ , To ensure that each equation has a **dependent variable**, then the matrix  $\\boldsymbol{\\Gamma}$  each column has at least one element of 1\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{equation}\n\\boldsymbol{\\Gamma} =\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1m} \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n\\gamma_{m1} & \\gamma_{m2} & \\cdots & \\gamma_{mm} \\\\\n\\end{bmatrix} \\\\\n\\text{if }\\Rightarrow\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1m} \\\\\n0 & \\gamma_{22} & \\cdots & \\gamma_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n0 & 0 & \\cdots & \\gamma_{mm} \\\\\n\\end{bmatrix}\n\\end{equation}\n$$\n\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{cases}\n\\begin{aligned}\ny_{1t} &=& f_{1}\\left(\\mathbf{x}_{t}\\right)+\\varepsilon_{t1} \\\\\ny_{2t} &=& f_{2}\\left(y_{t1}, \\mathbf{x}_{t}\\right)+\\varepsilon_{t2} \\\\\n& \\vdots & \\vdots \\\\\ny_{mt} &=& f_{m}\\left(y_{t1}, y_{t2}, \\ldots, \\mathbf{x}_{t}\\right)+\\varepsilon_{mt}\n\\end{aligned}\n\\end{cases}\n$$\n\n:::\n\n::::\n\n\n::: {.callout-note}\n\n- If matrix  $\\boldsymbol{\\Gamma}$  is upper triangular matrix, then the SEM is a **recursive** model system.\n\n- For the SEM solution to exist,  $\\boldsymbol{\\Gamma}$  must be **nonsingular**.\n:::\n\n::: {.notes}\nNow, let's focus the **[En]{.red}dogenous parameter matrix** firstly.\n:::\n\n##\n\n### Exdogenous coefficients matrix\n\nThe **[Ex]{.red}ogenous coefficients matrix** $\\boldsymbol{B}$ ：\n\n$$\n\\begin{equation}\n\\boldsymbol{B} =\n\\begin{bmatrix}\n\\beta_{11} & \\beta_{12} & \\cdots & \\beta_{1m} \\\\\n\\beta_{21} & \\beta_{22} & \\cdots & \\beta_{2m} \\\\\n\\cdots & \\cdots & \\cdots & \\cdots\\\\\n\\beta_{k1} & \\beta_{k2} & \\cdots & \\beta_{km} \\\\\n\\end{bmatrix}\n\\end{equation}\n$$\n\n::: {.notes}\nHere is the The **[Ex]{.red}ogenous coefficients matrix**.You should pay attention that the first column if SEM contains intercepts.\n:::\n\n## Reduced SEM\n\n<!-- some images insert here -->\n\n##\n\n### Algebraic expression\n\n**Reduced equations**:  The equation expresses an **endogenous variable** with all the **predetermined variables** and the **stochastic disturbances**.\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&=  & +\\pi_{11}X_{t1}+\\pi_{21}X_{t2} &+\\cdots+\\pi_{k1}X_{tk} & + v_{t1} \\\\\nY_{t2}&=&+\\pi_{12}X_{t1}+\\pi_{22}X_{t2} &+\\cdots+\\pi_{k2}X_{tk} & + v_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &  \\\\\nY_{tm}&=&+\\pi_{1m}X_{t1} +\\pi_{2m}X_{t2} &+\\cdots+\\pi_{km}X_{tk} & + v_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n::: {.notes}\nAs you see, we know well with the structural SEMs because we have learned thess models in the economic textbooks.Now, we will go ahead to  the important concept of reduced SEM.___So, a reduced equation is one that expresses an **endogenous variable** solely in terms of the **predetermined variables** and the **stochastic disturbances**.We denoted the reduced SEM as follows.\n:::\n\n##\n\n### Reduced coefficients and disturbance\n\n- **Reduced coefficients**: parameters in the reduced SEM.\n\n- **Reduced disturbance**: stochastic disturbance terms in the reduced SEM.\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&=  & +\\pi_{11}X_{t1}+\\pi_{21}X_{t2} &+\\cdots+\\pi_{k1}X_{tk} & + v_{t1} \\\\\nY_{t2}&=&+\\pi_{12}X_{t1}+\\pi_{22}X_{t2} &+\\cdots+\\pi_{k2}X_{tk} & + v_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &  \\\\\nY_{tm}&=&+\\pi_{1m}X_{t1} +\\pi_{2m}X_{t2} &+\\cdots+\\pi_{km}X_{tk} & + v_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n> Reduced coefficients:\n-  $\\pi_{11},\\pi_{21},\\cdots, \\pi_{k1}$  -  $\\pi_{1m},\\pi_{2m},\\cdots, \\pi_{km}$ .\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n> Reduced disturbance:\n-  $v_{1},v_2,\\cdots, v_m$ 。\n\n:::\n\n::::\n\n::: {.notes}\nHence, we induce the concepts of Reduced coefficients and Reduced disturbance.- Reduced coefficients are parameters in the reduced SEM, such as all $\\pi_{km}$s.- Reduced disturbance: stochastic disturbance terms in the reduced SEM, such as all $v_{m}$s.\n:::\n\n##\n\n### Matrix expression (1/2)\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&=  & +\\pi_{11}X_{t1}+\\pi_{21}X_{t2} &+\\cdots+\\pi_{k1}X_{tk} & + v_{t1} \\\\\nY_{t2}&=&+\\pi_{12}X_{t1}+\\pi_{22}X_{t2} &+\\cdots+\\pi_{k2}X_{tk} & + v_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &  \\\\\nY_{tm}&=&+\\pi_{1m}X_{t1} +\\pi_{2m}X_{t2} &+\\cdots+\\pi_{km}X_{tk} & + v_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\nFor this algebraic reduced SEM, we can note its matrix  form as:\n\n$$\n\\begin{equation}\n\\begin{bmatrix}\nY_1 & Y_2 & \\cdots & Y_m \\\\\n\\end{bmatrix} _t = \\\\\n\\begin{bmatrix}\nX_1 & X_2 & \\cdots & X_m \\\\\n\\end{bmatrix} _t\n\\begin{bmatrix}\n\\pi_{11} & \\pi_{12} & \\cdots & \\pi_{1m} \\\\\n\\pi_{21} & \\pi_{22} & \\cdots & \\pi_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n\\pi_{m1} & \\pi_{m2} & \\cdots & \\pi_{mm} \\\\\n\\end{bmatrix}  +\n\\begin{bmatrix}\nv_1 & v_2 & \\cdots & v_m \\\\\n\\end{bmatrix} _t\n\\end{equation}\n$$\n\n::: {.notes}\nAlso, we can denote the matrix form of the reduced SEM as below.\n:::\n\n##\n\n### Matrix expression (2/2)\n\nFor simplicity, the matrix expression of reduced SEM can be noted further.\n\n$$\n\\begin{aligned}\n& \\boldsymbol{y^{\\prime}_t} & =  &\\boldsymbol{x^{\\prime}_t} \\boldsymbol{\\Pi}  & + & \\boldsymbol{{v^{\\prime}_t}}  \\\\\n&(1 \\ast m) & & (1 \\ast k)(k \\ast m) & &  (1 \\ast m)\n\\end{aligned}\n$$\n\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- the reduced coefficients matrix is :\n\n$$\n\\begin{equation}\n\\boldsymbol{\\Pi} =\n\\begin{bmatrix}\n\\pi_{11} & \\pi_{12} & \\cdots & \\pi_{1m} \\\\\n\\pi_{21} & \\pi_{22} & \\cdots & \\pi_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n\\pi_{m1} & \\pi_{m2} & \\cdots & \\pi_{mm} \\\\\n\\end{bmatrix}\n\\end{equation}\n$$\n\n:::\n\n::: {.column width=\"15%\"}\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n- the reduced disturbances vector is:\n\n$$\n\\begin{equation}\n\\boldsymbol{{v^{\\prime}_t}}=\n\\begin{bmatrix}\nv_1 & v_2 & \\cdots & v_m \\\\\n\\end{bmatrix}_t\n\\end{equation}\n$$\n\n:::\n\n::::\n\n## Structural VS Reduced SEM\n\n<!---insert image here--->\n\n##\n\n### The two systems\n\nWe can induce Reduced Equations from Structural Equations:\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&= & &+\\gamma_{21}Y_{t2}+&\\cdots  &+\\gamma_{m1}Y_{tm} & +\\beta_{11}X_{1t}+\\beta_{21}X_{t2} &+\\cdots+\\beta_{k1}X_{tk} &+\\varepsilon_{t1} \\\\\nY_{t2}&=&\\gamma_{12}Y_{t1} &+  & \\cdots &+\\gamma_{m2}Y_{tm}&+\\beta_{12}X_{t1}+\\beta_{22}X_{t2} &+\\cdots+\\beta_{k2}X_{tk} &+\\varepsilon_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &&\\vdots  \\\\\nY_{tm}&=&\\gamma_{1m}Y_{t1}&+\\gamma_{2m}Y_{t2}+& \\cdots  & &+\\beta_{1m}X_{t1} +\\beta_{2m}X_{t2} &+\\cdots+\\beta_{km}X_{tk} &+\\varepsilon_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n\n$$\n\\Rightarrow\\begin{cases}\n\\begin{alignat}{5}\nY_{t1}&=  & +\\pi_{11}X_{t1}+\\pi_{21}X_{t2} &+\\cdots+\\pi_{k1}X_{tk} & + v_{t1} \\\\\nY_{t2}&=&+\\pi_{12}X_{t1}+\\pi_{22}X_{t2} &+\\cdots+\\pi_{k2}X_{tk} & + v_{t2}\\\\\n& \\vdots &\\vdots &&\\vdots &  \\\\\nY_{tm}&=&+\\pi_{1m}X_{t1} +\\pi_{2m}X_{t2} &+\\cdots+\\pi_{km}X_{tk} & + v_{tm}\n\\end{alignat}\n\\end{cases}\n$$\n\n::: {.notes}\nUntill now, we have two notation systems. one is the structural SEM, and the other is the reduced SEM.So, Why we need these two notation systems ?And what is the relationship between these two notation systems ?A short answer is that we can deduce the structural parameters with the reduced coefficients.\n:::\n\n##\n\n### Coefficients\n\nThe Structural SEM :\n\n$$\n\\begin{aligned}\n\\boldsymbol{y^{\\prime}_t} \\boldsymbol{\\Gamma} +  \\boldsymbol{x^{\\prime}_t} \\boldsymbol{B} =  \\boldsymbol{{\\varepsilon^{\\prime}_t}}\n\\end{aligned}\n$$\n\nThe Reduced SEM:\n\n$$\n\\begin{aligned}\n\\boldsymbol{y^{\\prime}_t}  =  \\boldsymbol{x^{\\prime}_t} \\boldsymbol{\\Pi}   +  \\boldsymbol{{v^{\\prime}_t}}\n\\end{aligned}\n$$\n\n\n::: {.callout-note}\n\n\n- where:\n\n$$\n\\begin{align}\n\\boldsymbol{\\Pi} &= - \\boldsymbol{B} \\boldsymbol{\\Gamma^{-1}}\\\\\n\\boldsymbol{{v^{\\prime}_t}} &= \\boldsymbol{{\\varepsilon^{\\prime}_t}} \\boldsymbol{\\Gamma}^{-1}\n\\end{align}\n$$\n\n\n- and:\n\n$$\n\\begin{equation}\n\\boldsymbol{\\Gamma} =\n\\begin{bmatrix}\n\\gamma_{11} & \\gamma_{12} & \\cdots & \\gamma_{1m} \\\\\n\\gamma_{21} & \\gamma_{22} & \\cdots & \\gamma_{2m} \\\\\n\\cdots & \\cdots & \\cdots  & \\cdots \\\\\n\\gamma_{m1} & \\gamma_{m2} & \\cdots & \\gamma_{mm} \\\\\n\\end{bmatrix}\n\\end{equation}\n$$\n\n:::\n\n\n::: {.notes}\nThis slide shows the relationship between the structural SEM and the reduced SEM.And the reduced coefficients equals negetive B times the inverse matrix of structural pars.\n\n$$\n\\begin{aligned}& \\boldsymbol{y^{\\prime}_t} & =  &-\\boldsymbol{x^{\\prime}_t} \\boldsymbol{B} \\boldsymbol{\\Gamma^{-1}} & + & \\boldsymbol{{\\varepsilon^{\\prime}_t}} \\boldsymbol{\\Gamma}^{-1}  \\\\&(1 \\ast m) & & (1 \\ast k)(k \\ast m)(m \\ast m) & &  (1 \\ast m)(m \\ast m)\\end{aligned}\n$$\n:::\n\n##\n\n### Moments\n\nNow we concern the first and second moments of the disturbance:\n\n- first , let us assumed the moments of  **structural disturbances** satisfy:\n\n$$\n\\begin{align}\n\\mathbf{E[\\varepsilon_t | x_t]} &= \\mathbf{0} \\\\\n\\mathbf{E[\\varepsilon_t \\varepsilon^{\\prime}_t |x_t]} &= \\mathbf{\\Sigma} \\\\\nE\\left[\\boldsymbol{\\varepsilon}_{t} \\boldsymbol{\\varepsilon}_{s}^{\\prime} | \\mathbf{x}_{t}, \\mathbf{x}_{s}\\right] &=\\mathbf{0}, \\quad \\forall t, s\n\\end{align}\n$$\n\n- then, we can prove that the **reduced disturbances** satify:\n\n$$\n\\begin{align}\nE\\left[\\mathbf{v}_{t} | \\mathbf{x}_{t}\\right] &=\\left(\\mathbf{\\Gamma}^{-1}\\right)^{\\prime} \\mathbf{0}=\\mathbf{0} \\\\ E\\left[\\mathbf{v}_{t} \\mathbf{v}_{t}^{\\prime} | \\mathbf{x}_{t}\\right] &=\\left(\\mathbf{\\Gamma}^{-1}\\right)^{\\prime} \\mathbf{\\Sigma} \\mathbf{\\Gamma}^{-1}=\\mathbf{\\Omega} \\\\\n\\text{where: }\\mathbf{\\Sigma} &=\\mathbf{\\Gamma}^{\\prime} \\mathbf{\\Omega} \\mathbf{\\Gamma}\n\\end{align}\n$$\n\n::: {.notes}\nThis slide shows the first and second moments of the disturbance on both structural and reduced SEM.First , let us assumed the moments of structural disturbances satisfy following moment conditions. which means that the structural disturbances are drawn from an M-variate distribution with zero conditional expectation and zero covariance.Then, we can prove that the reduced disturbances will also be zero conditional expectation and its variance-covariance matrix equals omega.Finaly, we know the relationship between these two variance-covariance matrix.We denote the relationship as Sigma equals transpose Gamma times Omega times Gamma.\n:::\n\n##\n\n### Useful expression* (1/2)\n\nIn a sample of data, each joint observation will be one row in a data matrix ( with  $T$  observations):\n\n$$\n\\begin{align}\n\\left[\\begin{array}{lll}{\\mathbf{Y}} & {\\mathbf{X}} & {\\mathbf{E}}\\end{array}\\right]=\\left[\\begin{array}{ccc}{\\mathbf{y}_{1}^{\\prime}} & {\\mathbf{x}_{1}^{\\prime}} & {\\boldsymbol{\\varepsilon}_{1}^{\\prime}} \\\\ {\\mathbf{y}_{2}^{\\prime}} & {\\mathbf{x}_{2}^{\\prime}} & {\\boldsymbol{\\varepsilon}_{2}^{\\prime}} \\\\ {\\vdots} & {} \\\\ {\\mathbf{y}_{T}^{\\prime}} & {\\mathbf{x}_{T}^{\\prime}} & {\\boldsymbol{\\varepsilon}_{T}^{\\prime}}\\end{array}\\right]\n\\end{align}\n$$\n\nthen the structural SEM is:\n\n$$\n\\begin{align}\n\\mathbf{Y} \\mathbf{\\Gamma}+\\mathbf{X} \\mathbf{B}=\\mathbf{E}\n\\end{align}\n$$\n\nthe first and second moment of structural disturbances is:\n\n$$\n\\begin{align}\nE[\\mathbf{E} | \\mathbf{X}] &=\\mathbf{0} \\\\\nE\\left[(1 / T) \\mathbf{E}^{\\prime} \\mathbf{E} | \\mathbf{X}\\right] &=\\mathbf{\\Sigma}\n\\end{align}\n$$\n\n::: {.notes}\nThe next two slides will show us some useful relationships under sample data set.I will not discuss them here, and you should try to learn this content by yourself.\n:::\n\n\n##\n\n### Useful expression*\n\n\nAssume that:\n\n$$\n\\begin{align}\n(1 / T) \\mathbf{X}^{\\prime} \\mathbf{X} & \\rightarrow \\mathbf{Q}  \\text{ ( a  finite positive definite matrix)} \\\\\n(1 / T) \\mathbf{X}^{\\prime} \\mathbf{E} & \\rightarrow \\mathbf{0}\n\\end{align}\n$$\n\nthen the reduced SEM can be noted as:\n\n$$\n\\begin{align}\n\\mathbf{Y} & =\\mathbf{X} \\boldsymbol{\\Pi}+\\mathbf{V} && \\leftarrow  \\mathbf{V}=\\mathbf{E} \\mathbf{\\Gamma}^{-1}\n\\end{align}\n$$\n\nAnd we may have following useful results：\n\n$$\n\\begin{align}\n\\frac{1}{T}\n\\begin{bmatrix}\n{\\mathbf{Y}^{\\prime}} \\\\\n{\\mathbf{X}^{\\prime}} \\\\\n{\\mathbf{V}^{\\prime}}\n\\end{bmatrix}\n\\begin{bmatrix}\n{\\mathbf{Y}} & {\\mathbf{X}} & {\\mathbf{V}}\n\\end{bmatrix}\n\\quad \\rightarrow  \\quad\n\\begin{bmatrix}\n{\\mathbf{I}^{\\prime} \\mathbf{Q} \\mathbf{I}+\\mathbf{\\Omega}} & {\\mathbf{I} \\mathbf{I}^{\\prime} \\mathbf{Q}} & {\\mathbf{\\Omega}} \\\\\n{\\mathbf{Q} \\mathbf{I}} & {\\mathbf{Q}} & {\\mathbf{0}^{\\prime}} \\\\ {\\mathbf{\\Omega}} & {\\mathbf{0}} & {\\mathbf{\\Omega}}\n\\end{bmatrix}\n\\end{align}\n$$\n\n::: {.notes}\nThe next two slides will show us some useful relationships under sample data set.I will not discuss them here, and you should try to learn this content by yourself.\n:::\n\n## Case 1: Keynesian income model\n\n<!---insert image here--->\n\n##\n\n### Structural SEM\n\nThe Keynesian model of income determination (structural SEM):\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= \\beta_0+\\beta_1Y_t+\\varepsilon_t &&\\text{(consumption function)}\\\\\nY_t &= C_t+I_t &&\\text{(income equity)}\n\\end{align}\n\\end{cases}\n$$\n\nSo the structural SEM contains:\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n2 **endogenous variables**:\n-  $c_t;Y_t$ \n\n:::\n\n\n::: {.column width=\"40%\"}\n\n\n1 **predetermined variables**:\n\n- 1 **exogenous variables**:  $I_t$ \n\n- 0 **lagged endogenous variable**.\n\n:::\n\n::::\n\n> **Exercise**: can you get the reduced SEM from this structural SEM ?\n\n::: {.notes}\nNow, I will show two cases to illustrate the relationship between the structural SEM and the reduced SEM. Here is the Keynesian model of income determination, and you know this is the structural SEM.So, can you deduce the reduced SEM from this structural SEM ?\n:::\n\n##\n\n### Reduced SEM\n\nWe can get the reduced SEM from the former structural SEM and denoted (the right):\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{cases}\n\\begin{align}\nY_t &=\\frac{\\beta_0}{1-\\beta_1}+\\frac{1}{1-\\beta_1}I_t+\\frac{\\varepsilon_t}{1-\\beta_1} \\\\\nC_t &=\\frac{\\beta_0}{1-\\beta_1}+\\frac{\\beta_1}{1-\\beta_1}I_t+\\frac{\\varepsilon_t}{1-\\beta_1}\n\\end{align}\n\\end{cases}\n$$\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{cases}\n\\begin{align}\nY_t &= \\pi_{11}+\\pi_{21}I_t+v_{t1} \\\\\nC_t &= \\pi_{12}+\\pi_{22}I_t+v_{t2}\n\\end{align}\n\\end{cases}\n$$\n:::\n\n::::\n\n\nwhere:\n\n$$\n\\begin{cases}\n\\begin{alignat}{5}\n&& \\pi_{11}  = \\frac{\\beta_0}{1-\\beta_1}; \\quad\n&& \\pi_{21}  = \\frac{\\beta_0}{1-\\beta_1}; \\quad\n&& v_{t1}  = \\frac{\\varepsilon_t}{1-\\beta_1};\\\\\n&& \\pi_{12}  = \\frac{1}{1-\\beta_1} ; \\quad\n&& \\pi_{22}  = \\frac{\\beta_1}{1-\\beta_1} ; \\quad\n&& v_{t2}  = \\frac{\\varepsilon_t}{1-\\beta_1};\n\\end{alignat}\n\\end{cases}\n$$\n\n>there are 2 **structural coefficients**  $\\beta_0;\\beta_1$  totally ； and 4 **reduced coefficients**  $\\pi_{11},\\pi_{21};\\pi_{12},\\pi_{22}$  (There are actually three only !)\n\n::: {.notes}\nSurely, We can get the reduced SEM from the former structural SEM with some simple algebraic calculation.Also, you can obtain the relationship between the structural parameters and the reduced coefficients.This is easy because the structural SEM contains only two equations and few structural parameters.\n:::\n\n## Case 2: Macroeconomic Model\n\n<!---insert image here--->\n\n##\n\n### Structural SEM\n\nConsider the **Small Macroeconomic Model** (Structural SEM):\n\n$$\n\\begin{cases}\n\\begin{aligned}\n\\text { consumption: }  c_{t} &=\\alpha_{0}+\\alpha_{1} y_{t}+\\alpha_{2} c_{t-1}+\\varepsilon_{t, c} \\\\\n\\text { investment: }  i_{t} &=\\beta_{0}+\\beta_{1} r_{t}+\\beta_{2}\\left(y_{t}-y_{t-1}\\right)+\\varepsilon_{t, j} \\\\\n\\text { demand: }  y_{t} &=c_{t}+i_{t}+g_{t}\n\\end{aligned}\n\\end{cases}\n$$\n\nwhere:  $c_t =$  consumption;  $y_t =$  output;  $i_t =$  investment;  $r_t =$  rate;  $g_t =$  government expenditure.\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n3 **endogenous variables**:  $c_t;i_t;Y_t$ \n\n4 **predetermined variables**:\n\n- 2 **exogenous variables**:  $r_t;g_t$ . - 2 **lagged endogenous variables**:  $y_{t-1};c_{t-1}$ \n\n:::\n\n\n::: {.column width=\"40%\"}\n\ntotally 6 **strutural coefficients**:  $\\alpha_0,\\alpha_1,\\alpha_2;\\beta_0,\\beta_1,\\beta_2;$ \n\n:::\n\n::::\n\n::: {.notes}\nSo, let's go ahead to more complex structural SEM with three equations.\n:::\n\n##\n\n### Reduced SEM\n\nWe can get the reduced SEM from the former structural SEM: (HOW TO??)\n\n$$\n\\begin{cases}\n\\begin{align}\nc_{t}  = &  [{\\alpha_{0}}{\\left(1-\\beta_{2}\\right)}+\\beta_{0} \\alpha_{1}+\\alpha_{1} \\beta_{1}  r_{t}+\\alpha_{1} g_{t}+\\alpha_{2}\\left(1-\\beta_{2}\\right) c_{t-1}-\\alpha_{1} \\beta_{2} y_{t-1} \\\\\n+&\\left(1-\\beta_{2}\\right) \\varepsilon_{t, c}+\\alpha_{1} \\varepsilon_{t, j}] /{\\Lambda} \\\\\ni_{t}  = & [\\alpha_{0} \\beta_{2}+\\beta_{0}\\left(1-\\alpha_{1}\\right)+\\beta_{1}\\left(1-\\alpha_{1}\\right) r_{t}+\\beta_{2} g_{t}+\\alpha_{2} \\beta_{2} c_{t-1}-\\beta_{2}\\left(1-\\alpha_{1}\\right) y_{t-1} \\\\\n+&\\beta_{2} \\varepsilon_{t, c}+\\left(1-\\alpha_{1}\\right) \\varepsilon_{t, j}]/{\\Lambda} \\\\\ny_{t} = & [\\alpha_{0}+\\beta_{0}+\\beta_{1} r_{t}+g_{t}+\\alpha_{2} c_{t-1}-\\beta_{2} y_{t-1}\n+\\varepsilon_{t, c}+\\varepsilon_{t, j}] /{\\Lambda}\n\\end{align}\n\\end{cases}\n$$\n\nwhere:  $\\Lambda = 1- \\alpha_1 -\\beta_2$ 。For simplicity, denote the **reduced SEM** as:\n\n$$\n\\begin{cases}\n\\begin{aligned}\nc_{t} & =  \\pi_{11} +\\pi_{21}r_t +\\pi_{31}g_t +\\pi_{41}c_{t-1} +\\pi_{51}y_{t-1} +v_{t1} \\\\\ni_{t} & =  \\pi_{12} +\\pi_{22}r_t +\\pi_{32}g_t +\\pi_{42}c_{t-1} +\\pi_{52}y_{t-1} +v_{t2} \\\\\ni_{t} & =  \\pi_{13} +\\pi_{23}r_t +\\pi_{33}g_t +\\pi_{43}c_{t-1} +\\pi_{53}y_{t-1} +v_{t3}\n\\end{aligned}\n\\end{cases}\n$$\n\n> So we have 15 **reduced coefficients** totally!\n\n::: {.notes}\nWith a little long time calculation, you can obtain the reduced SEM and also the relationship between the structural parameters and the reduced coefficients.Anyway, the calculation becomes complex and tedious for most of us.\n:::\n\n##\n\n### Thinking\n\n**Thinking**：\n\n- What are the purposes of structural SEM and reduced SEM respectively?\n\n- Note the consumption function (in structural SEM): the rate  $i_t$  does not impact the consumption  $c_t$ !\n\n- It will be obvious from the reduced SEM that  $\\frac{\\Delta c_t}{\\Delta r_t} = \\frac{\\alpha_1 \\beta_1}{\\Lambda}$ \n\n\n- Note the consumption function (in structural SEM): What are the reasons for the impact of income  $y_t$  on consumption  $c_t$ ?\n\n- It's also easy to get the answer by transformation:  $\\frac{\\Delta c_t}{ \\Delta y_t} = \\frac{\\Delta c_t / \\Delta r_t}{\\Delta y_t / \\Delta r_t} = \\frac{\\alpha_1 \\beta_1 / \\Lambda}{ \\beta_1 / \\Lambda} = \\alpha_1$ \n\n::: {.notes}\nSo, we shoul rethink that What is the use of structural SEM and reduced SEM respectively?Can we relieve the works by using alternative approaches?\n:::\n\n##\n\n### The relationship\n\nAccording to the relationship between Structural SEM and Reduced SEM:\n\n$$\n\\begin{aligned}\n\\boldsymbol{y^{\\prime}_t}  =  &-\\boldsymbol{x^{\\prime}_t} \\boldsymbol{\\Pi}   +  \\boldsymbol{{v^{\\prime}_t}}\n=  -\\boldsymbol{x^{\\prime}_t} \\boldsymbol{B} \\boldsymbol{\\Gamma^{-1}}  +  \\boldsymbol{{\\varepsilon^{\\prime}_t}} \\boldsymbol{\\Gamma}^{-1}\n\\end{aligned}\n$$\n\nThen, the following matrixes can be easily obtained:\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{align}\n\\mathbf{y}^{\\prime} & =\n\\begin{bmatrix}\nc & i & y\n\\end{bmatrix}\\\\\n\\boldsymbol{x}^{\\prime} & =\n\\begin{bmatrix}\n1 & r & g & c_{-1} & y_{-1}\n\\end{bmatrix}\n\\end{align}\n$$\n\n$$\n\\begin{align}\n\\mathbf{B}=\n\\begin{bmatrix}\n{-\\alpha_{0}} & {-\\beta_{0}} & {0} \\\\\n{0} & {-\\beta_{1}} & {0} \\\\\n{0} & {0} & {-1} \\\\ {-\\alpha_{2}} & {0} & {0} \\\\\n{0} & {\\beta_{2}} & {0}\n\\end{bmatrix}\n\\end{align}\n$$\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n$$\n\\begin{align}\n\\Gamma &=\n\\begin{bmatrix}\n{1} & {0} & {-1} \\\\\n{0} & {1} & {-1} \\\\\n{-\\alpha_{1}} & {-\\beta_{2}} & {1}\n\\end{bmatrix} \\\\\n\\mathbf{\\Gamma}^{-1} &=\\frac{1}{\\Lambda}\n\\begin{bmatrix}\n{1-\\beta_{2}} & {\\beta_{2}} & {1} \\\\\n{\\alpha_{1}} & {1-\\alpha_{1}} & {1} \\\\\n{\\alpha_{1}} & {\\beta_{2}} & {1}\n\\end{bmatrix}\n\\end{align}\n$$\n\n:::\n\n::::\n\n::: {.notes}\nHere, we will obtain the reduced coefficients with matrix algebraic calculation.And you should first know the relationship between Structural SEM and Reduced SEM.Then, we write down the following vectors and matrixes. Y`, X`,Gamma, B, and inverse Gamma.Note that the first element of the vector X' is constant one for the intercept in our equations.I think the difficulty in this calculation is the inverse of matrix Gamma.\n:::\n\n\n##\n\n### Calculations\n\nWe can get the same answers: (It's so easy!)\n\n$$\n\\begin{align}\n\\boldsymbol{\\Pi=-B\\Gamma^{-1}}=\\frac{1}{\\Lambda}\n\\begin{bmatrix}\n{\\alpha_{0}\\left(1-\\beta_{2}\\right)+\\beta_{0} \\alpha_{1}} & {\\alpha_{0} \\beta_{2}+\\beta_{0}\\left(1-\\alpha_{1}\\right)} &  {\\alpha_{0}+\\beta_{0}}   \\\\\n{\\alpha_{1} \\beta_{1}} & {\\beta_{1}\\left(1-\\alpha_{1}\\right)} &  \\beta_1  \\\\\n{\\alpha_{1}} & {\\beta_{2}} & 1 \\\\\n{\\alpha_{2}\\left(1-\\beta_{2}\\right)}& {\\alpha_{2} \\beta_{2}} & \\alpha_2\\\\\n{-\\beta_{2} \\alpha_{1}} & {-\\beta_{2}\\left(1-\\alpha_{1}\\right)} &-\\beta_2\n\\end{bmatrix}\n\\end{align}\n$$\n\n\n\n$$\n\\begin{align}\n\\mathbf{\\Pi}^{\\prime}=\\frac{1}{\\Lambda}\n\\begin{bmatrix}\n\\alpha_{0}\\left(1-\\beta_{2}\\right)+\\beta_{0} \\alpha_{1} & \\alpha_{1} \\beta_{1} & \\alpha_{1} & \\alpha_{2}\\left(1-\\beta_{2}\\right) & -\\beta_{2} \\alpha_{1} \\\\\n\\alpha_{0} \\beta_{2}+\\beta_{0}\\left(1-\\alpha_{1}\\right) & \\beta_{1}\\left(1-\\alpha_{1}\\right) & \\beta_{2} & \\alpha_{2} \\beta_{2} & -\\beta_{2}\\left(1-\\alpha_{1}\\right) \\\\\n\\alpha_{0}+\\beta_{0} & \\beta_{1} & 1 & \\alpha_{2} & -\\beta_{2}\n\\end{bmatrix}\n\\end{align}\n$$\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n- Where:\n\n$$\n\\Lambda = 1- \\alpha_1 -\\beta_2\n$$\n\n:::\n\n\n::: {.column width=\"40%\"}\n\n- Remeber that:\n\n$$\n\\begin{align}\n\\mathbf{x}^{\\prime}  =\n\\begin{bmatrix} 1 & r & g & c_{-1} & y_{-1}\n\\end{bmatrix}\n\\end{align}\n$$\n:::\n\n::::\n\n::: {.notes}\nNow, we know that the reduced coefficients matrix equal to negtive B times inverse Gamma.with the matrix agebraic caculation, we finally get the result here.And you can compare the transpose Pi with the former result.___So, Matrix calculation is a sharp knife, handy and sharp!You should practice by yourself at least once.\n:::\n\n## Supplement\n\n<!-- insert image here -->\n\n##\n\n### Inverse matrix solution and procedure*\n\n\nUse the elementary row operation (Gauss-Jordan) to find the inverse matrix:\n\n1. Construct **augmented matrix**\n\n2. Transform the augmented matrix for many times until the goal is achieved.\n\n\nUse cofactor, algebraic cofactor and adjoint matrix to get the inverse matrix:\n\n1. Calculate **cofactor matrix** and **algebraic cofactor matrix**;\n\n2. Calculate **adjoint matrix**: it is the **transpose** of the cofactor matrix;\n\n3. Calculate the **determinant** of original matrix : each element of **top row** in the original matrix is multiplied by its corresponding **top row** element in the \"cofactor matrix\";\n\n4. Calculated the inverse matrix: **1/ determinant**  $\\times$  **adjoint matrix**\n\n\n\n::: {.notes}\nThis slide gives you the solution and procedure to obtain the inverse matrix.And please try to practice by yourself.A.用初等行运算（高斯－若尔当）来求逆矩阵：1. 构造**增广矩阵**2. 对增广矩阵进行多次变换，直至达到目标。<br>B.用余子式、代数余子式和伴随矩阵来求逆矩阵1. 计算**余子式矩阵**和**代数余子式矩阵**2. 计算**伴随矩阵**：就是代数余子式矩阵的**转置**3. 计算原矩阵**行列式**：原矩阵**顶行**的每个元素乘以其对应\"代数余子式矩阵\"**顶行**元素。4. 计算得出逆矩阵：**1/行列式** X **伴随矩阵**\n:::\n\n\n# 18.3 Is the OLS Method Still applicable ?{#OLS-apply .monash-bg-blue .mcenter}\n\n::: {.notes}\nIn this section, we will discuss the problems with the SEM by using OLS method directly.\n:::\n\n\n## Endogenous variable problem (1/2)\n\nConsider Keynes's model of income determination, We will be able to show that  $Y_t$  and  $u_t$  will be correlated, thus violating the CLRM **A2** assumption.\n\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= \\beta_0+\\beta_1Y_t+u_t   &(0<\\beta_1<1)  &&\\text{( consumption function)}\\\\\nY_t &= C_t+I_t  & &&\\text{(Income Identity)}\n\\end{align}\n\\end{cases}\n$$\n\nBy transforming the above structural equation, we obtained:\n\n$$\n\\begin{align}\nY_t &= \\beta_0+\\beta_1Y_t+ I_t +u_t   \\\\\nY_t &= \\frac{\\beta_0}{1-\\beta_1}+\\frac{1}{1-\\beta_1}I_t+\\frac{1}{1-\\beta_1}u_t   && \\text{(eq1: Reduced equation)}\\\\\nE(Y_t)&=\\frac{\\beta_0}{1-\\beta_1}+\\frac{1}{1-\\beta_1}I_t && \\text{(eq2: Take the expectation for both sides)}\n\\end{align}\n$$\n\n::: {.notes}\nTake Keynes's model of income determination. We will be able to show that  $Y_t$  and  $u_t$  will be correlated, thus violating the CLRM assumption.Here, we transform the structural SEM and get the reduced equation for the endogenous variable Y_t.\n:::\n\n\n## Endogenous variable problem (2/2)\n\nFurther more:\n\n$$\n\\begin{align}\nY_t - E(Y_t)& = \\frac{u_t}{1-\\beta_1} && \\text{(eq 1 - eq 2)}\\\\\nu_t-E(u_t) &= u_t && \\text{(eq 3: Expectation is equal to 0)} \\\\\ncov(Y_t,u_t) &= E([Y_t-E(Y_t)][u_t-E(u_t)])  && \\text{(eq 4: Covariance definition)}\\\\\n&=\\frac{E(u^2_t)}{1-\\beta_1} && \\text{(eq 5: Variance definition)}\\\\\n&=\\frac{\\sigma^2}{1-\\beta_1}\\neq 0 && \\text{(eq 6: The variance is not 0)}\n\\end{align}\n$$\n\n- Therefore, the consumption equation of the Keynesian model will not satisfy the CLRM A2 assumption.\n\n- Thus, OLS method cannot be used to obtain **Best linear unbiased estimator** (BLUE) for consumption equation.\n\n\n::: {.notes}\nHere, I give you the hints to obtain the covariance of Y_t and u_t.And we can prove that the demand equation of the Keynesian model will not satisfy the assumption that  $Y_t$  is not related to  $u_t$  in the CLRM hypothesis.Thus, OLS method cannot be used to obtain **Best linear unbiased estimator** (BLUE) for demand equation.\n:::\n\n\n## The OLS estimator of the coefficient is biased\n\nFurthermore, the OLS estimator is biased to its true  $\\beta_1$ , which means  $E(\\hat{\\beta}_1) \\neq \\beta_1$ . The proof show as below.\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= \\beta_0+\\beta_1Y_t+u_t   &(0<\\beta_1<1)  &&\\text{( consumption function)}\\\\\nY_t &= C_t+I_t  & &&\\text{(Income Identity)}\n\\end{align}\n\\end{cases}\n$$\n\n$$\n\\begin{align}\n\\hat{\\beta}_1\n= \\frac{\\sum{c_ty_t}}{\\sum{y^2_t}}\n= \\frac{\\sum{C_ty_t}}{\\sum{y^2_t}}\n= \\frac{\\sum{\\left [ (\\beta_0+\\beta_1Y_t+u_t)y_t \\right ]}}{\\sum{y^2_t}}\n= \\beta_1 + \\frac{\\sum{u_ty_t}}{\\sum{y^2_t}}\n&& \\text{(eq 1)}\n\\end{align}\n$$\n\nTake the expectation of both sides in eq 1, so:\n\n$$\n\\begin{align}\nE(\\hat{\\beta}_1) &= \\beta_1 + E \\left ( \\frac{\\sum{u_ty_t}}{\\sum{y^2_t}} \\right )\n\\end{align}\n$$\n\n> Question: is the expactation  $E\\left (\\frac {\\sum {u_ty_t}} {\\sum {y^2_t}} \\right)$   equal to zero?\n\n::: {.notes}\nIt will be further demonstrated that the OLS method is biased to estimate  $\\beta_1$ , whicn means  $E(\\hat{\\beta}_1) \\neq \\beta_1$ .___- The following question is that if the expactation  $E\\left (\\frac {\\sum {u_ty_t}} {\\sum {y^2_t}} \\right)$  is equal to zero?- We can prove that it will not be equal to 0 with the following two slides from proof appendix 1 to appendix 2.I will not try to discuss the details for these provement here, so you should do this after our lessons.\n:::\n\n## Supplement\n\n<!---insert image here--->\n\n##\n\n### Proof 1/2\n\n$$\n\\begin{align}\n\\frac{\\sum{c_ty_t}}{\\sum{y^2_t}}\n&= \\frac{\\sum{(C_t-\\bar{C})(Y_t - \\bar{Y})}}{\\sum{y^2_t}}\n= \\frac{\\sum{(C_t-\\bar{C})y_t}}{\\sum{y^2_t}} \\\\\n& =\\frac{\\sum{C_ty_t}-\\sum{\\bar{C}y_t}}{\\sum{y^2_t}}\n=\\frac{\\sum{C_ty_t}-\\sum{\\bar{C}(Y_t- \\bar{Y})}}{\\sum{y^2_t}} \\\\\n& = \\frac{\\sum{C_ty_t}-\\bar{C}\\sum{Y_t}- \\sum{\\bar{C}\\bar{Y}}}{\\sum{y^2_t}}\n= \\frac{\\sum{C_ty_t}-\\bar{C}\\sum{Y_t}- n{\\bar{C}\\bar{Y}}}{\\sum{y^2_t}}\n= \\frac{\\sum{C_ty_t}}{\\sum{y^2_t}}\n\\end{align}\n$$\n\n$$\n\\begin{align}\n\\hat{\\beta_1} & = \\frac{\\sum\\left(\\beta_{0}+\\beta_{1} Y_{t}+u_{t}\\right) y_{t}}{\\sum y_{t}^{2}}\n= \\frac{\\sum{\\beta_{0}y_t} +\\sum{\\beta_1Y_ty_t}+\\sum{u_{t}y_t} }{\\sum y_{t}^{2}} \\\\\n& = \\frac{\\beta_1\\sum{(y_t+\\bar{Y})y_t}+\\sum{u_{t}y_t} }{\\sum y_{t}^{2}}\n=\\beta_{1}+\\frac{\\sum y_{t} u_{t}}{\\sum y_{t}^{2}}\n\\end{align}\n$$\n\n$$\n\\begin{align}\n\\Leftarrow &\\sum{y_t} =0  ; &&  \\frac{\\sum{Y_ty_t}}{y^2_t} = 1\n\\end{align}\n$$\n\n\n##\n\n### Proof 2/2\n\nConduct the limit to probability:\n\n$$\n\\begin{align}\n\\operatorname{plim}\\left(\\hat{\\beta}_{1}\\right) &=\\operatorname{plim}\\left(\\beta_{1}\\right)+\\operatorname{plim}\\left(\\frac{\\sum y_{t} u_{t}}{\\sum y_{t}^{2}}\\right) \\\\\n&=\\operatorname{plim}\\left(\\beta_{1}\\right)+\\operatorname{plim}\\left(\\frac{\\sum y_{t} u_{t} / n}{\\sum y_{t}^{2} / n}\\right) =\\beta_{1}+\\frac{\\operatorname{plim}\\left(\\sum y_{t} u_{t} / n\\right)}{\\operatorname{plim}\\left(\\sum y_{t}^{2} / n\\right)}\n\\end{align}\n$$\n\nAnd we've shown that:\n\n$$\n\\begin{align}\ncov(Y_t,u_t) &= E([Y_t-E(Y_t)][u_t-E(u_t)])  =\\frac{E(u^2_t)}{1-\\beta_1}\n=\\frac{\\sigma^2}{1-\\beta_1}\\neq 0\n\\end{align}\n$$\n\nTherefore we finaly prove:  $E \\left ( \\frac{\\sum{u_ty_t}}{\\sum{y^2_t}} \\right ) \\neq 0$ \n\n\n## Simulation\n\n<!---insert image here--->\n\n##\n\n### Artificially population\n\nHere, we construct an artificially controlled population for our Keynes's SEM model.\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= \\beta_0+\\beta_1Y_t+u_t   &(0<\\beta_1<1)  &&\\text{(consumption function)}\\\\\nY_t &= C_t+I_t  & &&\\text{(Income Identity)}\n\\end{align}\n\\end{cases}\n$$\n\n$$\n\\begin{cases}\n\\begin{align}\nC_t &= 2+ 0.8Y_t+u_t   &(0<\\beta_1<1)  &&\\text{(consumption function)}\\\\\nY_t &= C_t+I_t  & &&\\text{(Income Identity)}\n\\end{align}\n\\end{cases}\n$$\n\nThe artificially controlled population is set to:\n\n- $\\beta_0=2, \\beta_1=0.8, I_t \\leftarrow \\text{given values}$\n- $E(u_t)=0, var(u_t)=\\sigma^2=0.04$\n- $E(u_tu_{t+j})=0,j \\neq 0$\n- $cov(u_t,I_t)=0$\n\n::: {.notes}\nI will give you a numerical simulation to illustrate the problems with SEM by using OLS method directly.Here, we construct an artificially (/ˌɑːtɪˈfɪʃəli/) controlled population for our Keynes's SEM model.As you see, we control the population by setting following parameters and relationships.\n:::\n\n\n##\n\n### The data sets\n\nThe simulation data under given conditions are:\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n\n```{=html}\n<div class=\"datatables html-widget html-fill-item\" id=\"htmlwidget-3439a028991d788a8f63\" style=\"width:100%;height:auto;\"></div>\n<script type=\"application/json\" data-for=\"htmlwidget-3439a028991d788a8f63\">{\"x\":{\"filter\":\"none\",\"vertical\":false,\"caption\":\"<caption><\\/caption>\",\"data\":[[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\",\"11\",\"12\",\"13\",\"14\",\"15\",\"16\",\"17\",\"18\",\"19\",\"20\"],[18.15697,19.5998,21.93468,21.55145,21.88427,22.42648,25.4094,22.69523,24.36465,24.39334,24.09215,24.8745,25.3158,26.30465,25.78235,26.08018,27.2444,28.00963,30.89301,28.98706],[16.15697,17.5998,19.73468,19.35145,19.48427,20.02648,22.8094,20.09523,21.56465,21.59334,21.09215,21.8745,22.1158,23.10465,22.38235,22.68018,23.6444,24.40963,27.09301,25.18706],[2,2,2.2,2.2,2.4,2.4,2.6,2.6,2.8,2.8,3,3,3.2,3.2,3.4,3.4,3.6,3.6,3.8,3.8],[-0.3686059999999998,-0.08004000000000033,0.1869359999999993,0.1102899999999991,-0.02314600000000411,0.08529599999999604,0.4818799999999968,-0.06095399999999884,0.0729299999999995,0.0786680000000004,-0.1815700000000007,-0.0251000000000019,-0.1368399999999994,0.06092999999999904,-0.2435300000000034,-0.1839639999999996,-0.1511199999999988,0.00192599999999743,0.3786019999999972,-0.002588000000002921]],\"container\":\"<table class=\\\"display\\\">\\n  <thead>\\n    <tr>\\n      <th> <\\/th>\\n      <th>Y<\\/th>\\n      <th>C<\\/th>\\n      <th>I<\\/th>\\n      <th>u<\\/th>\\n    <\\/tr>\\n  <\\/thead>\\n<\\/table>\",\"options\":{\"dom\":\"tip\",\"pageLength\":8,\"rownames\":false,\"columnDefs\":[{\"targets\":1,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":2,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"targets\":4,\"render\":\"function(data, type, row, meta) {\\n    return type !== 'display' ? data : DTWidget.formatRound(data, 4, 3, \\\",\\\", \\\".\\\", null);\\n  }\"},{\"className\":\"dt-center\",\"targets\":\"_all\"},{\"visible\":false,\"targets\":0},{\"orderable\":false,\"targets\":0},{\"name\":\" \",\"targets\":0},{\"name\":\"Y\",\"targets\":1},{\"name\":\"C\",\"targets\":2},{\"name\":\"I\",\"targets\":3},{\"name\":\"u\",\"targets\":4}],\"digits\":4,\"order\":[],\"autoWidth\":false,\"orderClasses\":false,\"lengthMenu\":[8,10,25,50,100]}},\"evals\":[\"options.columnDefs.0.render\",\"options.columnDefs.1.render\",\"options.columnDefs.2.render\"],\"jsHooks\":[]}</script>\n```\n\n:::\n:::\n\n\n\n\n\n##\n\n### Manual calculation\n\nAccording to the above formula, the regression coefficient can be calculated as follows:\n\nEasy to calculate:  $\\sum{u_ty_t}$ \n=3.8000\n\nAnd:  $\\sum{y^2_t}$ \n=184.0000\n\nAnd:  $\\frac{\\sum{u_ty_t}}{\\sum{y^2_t}}$ \n=0.0207\n\nHence：  $\\hat{\\beta}_1 = \\beta_1 + \\frac{\\sum{u_ty_t}}{\\sum{y^2_t}}$ \n=0.8+0.0207= 0.8207\n\nThis also means that  $\\hat{\\beta_1}$  is different from  $\\beta_1=0.8$ , and the differnce is 0.0207.\n\n::: {.notes}\nAccording to the former provment procedure, we can manually calculate the OLS coefficient of beta_1.Finally, the OLS estimator of beta_1 equals 0.8207, and not equal to its true value 0.8 we have set before.So, the OLS estimator is biased with our simulation data set.\n:::\n\n\n##\n\n### Scatter plots\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The scatter of Y and C](images/lecture-18-sem-why.rmarkdown/fig-scatter-YC-1.png){#fig-scatter-YC fig-align='center' width=960}\n:::\n:::\n\n\n\n\n::: {.notes}\nHere, we draw the scatter of Y and C.\n:::\n\n\n##\n\n### Regression report 1\n\nNext, we used the simulated data for R analysis to obtain the original OLS report.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = mod_monte$mod.C, data = monte)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.27001 -0.15855 -0.00126  0.09268  0.46310 \n\nCoefficients:\n            Estimate Std. Error t value Pr(>|t|)    \n(Intercept)  1.49402    0.35413   4.219 0.000516 ***\nY            0.82065    0.01434  57.209  < 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.1946 on 18 degrees of freedom\nMultiple R-squared:  0.9945,\tAdjusted R-squared:  0.9942 \nF-statistic:  3273 on 1 and 18 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\n\n\n\n\n##\n\n### Regression report 2\n\nThe tidy report of OLS estimation shows below.\n\n\n\n\n::: {.cell layout-align=\"center\"}\n$$\n\\begin{alignedat}{999}\n\\begin{split}\n&\\widehat{C}=&&+1.49&&+0.82Y_i\\\\ \n&(s)&&(0.3541)&&(0.0143)\\\\ \n&(t)&&(+4.22)&&(+57.21)\\\\ \n&(fit)&&R^2=0.9945&&\\bar{R}^2=0.9942\\\\ \n&(Ftest)&&F^*=3272.87&&p=0.0000\n\\end{split}\n\\end{alignedat}\n$$\n:::\n\n\n\n\n$$\n\\begin{alignedat}{999}\n&\\widehat{C}=&&+1.49&&+0.82Y\\\\\n&\\text{(t)}&&(4.2188)&&(57.2090)\\\\\n&\\text{(se)}&&(0.3541)&&(0.0143)\\\\\n&\\text{(fitness)}&& n=20;&& R^2=0.9945;&& \\bar{R^2}=0.9942\\\\\n& && F^{\\ast}=3272.87;&& p=0.0000\\\\\n\\end{alignedat}\n$$\n\n::: {.notes}\nfor sum, The results of direct use of OLS regression also show bias.\n:::\n\n\n##\n\n### Sample regression line (SRL)\n\n\n\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![The SRL](images/lecture-18-sem-why.rmarkdown/fig-scatter-YC-fit-1.png){#fig-scatter-YC-fit fig-align='center' width=960}\n:::\n:::\n\n\n\n\n::: {.notes}\nAnd the OLS slope is 0.8207.\n:::\n\n\n##\n\n### Conclusions and points\n\nSo let's summarize this chapter.\n\n- Compared with the single-equation model, the SEM involves more than one dependent or endogenous variable. So there must be as many equations as  endogenous variables.\n\n- SEM always show that the endogenous variables are correlated with stochastic terms in other equations.\n\n\n- Classical OLS may not be appropriate because the estimators are inconsistent.\n\n\n::: {.notes}\nIn the next chapter, we will learn the identification of SEM.See you in my next class. Goodbye.\n:::\n\n\n## Reference\n\n\n- [SimultaneousEq.pdf](https://web.sgh.waw.pl/~mrubas/AdvEcon/pdf/T3_SimultaneousEq.pdf)\n\n\n## End Of This Chapter{.center-h background-color=\"aliceblue\"  background-image=\"pic/thank-you-gif-funny-little-yellow.gif\" background-size=\"600px\"  background-position=\"center\" background-opacity=\"0.8\" style=\"font-size:75px !important\"}\n\n",
    "supporting": [
      "lecture-18-sem-why_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../site_libs/htmltools-fill-0.5.8.1/fill.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/htmlwidgets-1.6.4/htmlwidgets.js\"></script>\n<link href=\"../site_libs/datatables-css-0.0.0/datatables-crosstalk.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/datatables-binding-0.33/datatables.js\"></script>\n<script src=\"../site_libs/jquery-3.6.0/jquery-3.6.0.min.js\"></script>\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css\" rel=\"stylesheet\" />\n<link href=\"../site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js\"></script>\n<link href=\"../site_libs/crosstalk-1.2.1/css/crosstalk.min.css\" rel=\"stylesheet\" />\n<script src=\"../site_libs/crosstalk-1.2.1/js/crosstalk.min.js\"></script>\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}